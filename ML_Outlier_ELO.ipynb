{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addressing outliers in the Kaggle ELO chanllege"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel is inspired by https://www.kaggle.com/waitingli/combining-your-model-with-a-model-without-outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chaogao/anaconda/lib/python3.6/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_9.4.1) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import mean_squared_error,log_loss\n",
    "\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)    \n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the model without outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.2 s, sys: 632 ms, total: 10.9 s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_df = pd.read_csv('../train_v4_agg.csv')\n",
    "test_df = pd.read_csv('../test_v4_agg.csv')\n",
    "\n",
    "#train_df = reduce_mem_usage(train_df)\n",
    "#test_df = reduce_mem_usage(test_df)\n",
    "#del train_df['Unnamed: 0']\n",
    "#del test_df['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>target</th>\n",
       "      <th>elasped_time</th>\n",
       "      <th>hist_hist_transactions_count</th>\n",
       "      <th>hist_category_1_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>city_id_purchase_amount_min</th>\n",
       "      <th>city_id_purchase_amount_max</th>\n",
       "      <th>city_id_purchase_amount_std</th>\n",
       "      <th>category_1_installments_mean</th>\n",
       "      <th>category_1_installments_min</th>\n",
       "      <th>category_1_installments_max</th>\n",
       "      <th>category_1_installments_std</th>\n",
       "      <th>authorized_flag_mean</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.820283</td>\n",
       "      <td>245</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.606593</td>\n",
       "      <td>-0.296112</td>\n",
       "      <td>0.155803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.392913</td>\n",
       "      <td>396</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.725956</td>\n",
       "      <td>-0.725956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688056</td>\n",
       "      <td>549</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.700326</td>\n",
       "      <td>-0.700326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142495</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.665244</td>\n",
       "      <td>-0.662910</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.159749</td>\n",
       "      <td>92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.671174</td>\n",
       "      <td>-0.326762</td>\n",
       "      <td>0.150674</td>\n",
       "      <td>1.220588</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.395148</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 first_active_month          card_id  feature_1  feature_2  \\\n",
       "0           0         2017-06-01  C_ID_92a2005557          5          2   \n",
       "1           1         2017-01-01  C_ID_3d0044924f          4          1   \n",
       "2           2         2016-08-01  C_ID_d639edf6cd          2          2   \n",
       "3           3         2017-09-01  C_ID_186d6a6901          4          3   \n",
       "4           4         2017-11-01  C_ID_cdbd2c0db2          1          3   \n",
       "\n",
       "   feature_3    target  elasped_time  hist_hist_transactions_count  \\\n",
       "0          1 -0.820283           245                          13.0   \n",
       "1          0  0.392913           396                          11.0   \n",
       "2          0  0.688056           549                           2.0   \n",
       "3          0  0.142495           153                           NaN   \n",
       "4          0 -0.159749            92                           5.0   \n",
       "\n",
       "   hist_category_1_sum  ...    city_id_purchase_amount_min  \\\n",
       "0                  0.0  ...                      -0.606593   \n",
       "1                  2.0  ...                      -0.725956   \n",
       "2                  0.0  ...                      -0.700326   \n",
       "3                  NaN  ...                      -0.665244   \n",
       "4                  3.0  ...                      -0.671174   \n",
       "\n",
       "   city_id_purchase_amount_max  city_id_purchase_amount_std  \\\n",
       "0                    -0.296112                     0.155803   \n",
       "1                    -0.725956                          NaN   \n",
       "2                    -0.700326                          NaN   \n",
       "3                    -0.662910                     0.001650   \n",
       "4                    -0.326762                     0.150674   \n",
       "\n",
       "   category_1_installments_mean  category_1_installments_min  \\\n",
       "0                      0.000000                     0.000000   \n",
       "1                      1.000000                     1.000000   \n",
       "2                      0.000000                     0.000000   \n",
       "3                      0.833333                     0.666667   \n",
       "4                      1.220588                     0.941176   \n",
       "\n",
       "   category_1_installments_max  category_1_installments_std  \\\n",
       "0                          0.0                          NaN   \n",
       "1                          1.0                          NaN   \n",
       "2                          0.0                          NaN   \n",
       "3                          1.0                     0.235702   \n",
       "4                          1.5                     0.395148   \n",
       "\n",
       "   authorized_flag_mean  year  month  \n",
       "0              0.950000  2017      6  \n",
       "1              0.968571  2017      1  \n",
       "2              0.953488  2016      8  \n",
       "3              1.000000  2017      9  \n",
       "4              0.962406  2017     11  \n",
       "\n",
       "[5 rows x 176 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    199710\n",
       "1      2207\n",
       "Name: outliers, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['outliers'] = 0\n",
    "train_df.loc[train_df['target']<-30,'outliers']=1\n",
    "train_df['outliers'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['outliers'] == 0]\n",
    "target = train_df['target']\n",
    "#del train_df['target']\n",
    "to_drop = ['target','Unnamed: 0']\n",
    "train_df.drop(labels=to_drop ,axis = 1,inplace = True)\n",
    "test_df.drop('Unnamed: 0',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_active_month</th>\n",
       "      <th>card_id</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>elasped_time</th>\n",
       "      <th>hist_hist_transactions_count</th>\n",
       "      <th>hist_category_1_sum</th>\n",
       "      <th>hist_category_1_mean</th>\n",
       "      <th>hist_category_2_1.0_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>city_id_purchase_amount_max</th>\n",
       "      <th>city_id_purchase_amount_std</th>\n",
       "      <th>category_1_installments_mean</th>\n",
       "      <th>category_1_installments_min</th>\n",
       "      <th>category_1_installments_max</th>\n",
       "      <th>category_1_installments_std</th>\n",
       "      <th>authorized_flag_mean</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>outliers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-06-01</td>\n",
       "      <td>C_ID_92a2005557</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>245</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.296112</td>\n",
       "      <td>0.155803</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>2017</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>C_ID_3d0044924f</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>396</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.725956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.968571</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-08-01</td>\n",
       "      <td>C_ID_d639edf6cd</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>549</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.700326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.953488</td>\n",
       "      <td>2016</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>C_ID_186d6a6901</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.662910</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.235702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2017</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>C_ID_cdbd2c0db2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.326762</td>\n",
       "      <td>0.150674</td>\n",
       "      <td>1.220588</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.395148</td>\n",
       "      <td>0.962406</td>\n",
       "      <td>2017</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 175 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  first_active_month          card_id  feature_1  feature_2  feature_3  \\\n",
       "0         2017-06-01  C_ID_92a2005557          5          2          1   \n",
       "1         2017-01-01  C_ID_3d0044924f          4          1          0   \n",
       "2         2016-08-01  C_ID_d639edf6cd          2          2          0   \n",
       "3         2017-09-01  C_ID_186d6a6901          4          3          0   \n",
       "4         2017-11-01  C_ID_cdbd2c0db2          1          3          0   \n",
       "\n",
       "   elasped_time  hist_hist_transactions_count  hist_category_1_sum  \\\n",
       "0           245                          13.0                  0.0   \n",
       "1           396                          11.0                  2.0   \n",
       "2           549                           2.0                  0.0   \n",
       "3           153                           NaN                  NaN   \n",
       "4            92                           5.0                  3.0   \n",
       "\n",
       "   hist_category_1_mean  hist_category_2_1.0_mean    ...     \\\n",
       "0              0.000000                  1.000000    ...      \n",
       "1              0.181818                  0.818182    ...      \n",
       "2              0.000000                  0.000000    ...      \n",
       "3                   NaN                       NaN    ...      \n",
       "4              0.600000                  0.000000    ...      \n",
       "\n",
       "   city_id_purchase_amount_max  city_id_purchase_amount_std  \\\n",
       "0                    -0.296112                     0.155803   \n",
       "1                    -0.725956                          NaN   \n",
       "2                    -0.700326                          NaN   \n",
       "3                    -0.662910                     0.001650   \n",
       "4                    -0.326762                     0.150674   \n",
       "\n",
       "   category_1_installments_mean  category_1_installments_min  \\\n",
       "0                      0.000000                     0.000000   \n",
       "1                      1.000000                     1.000000   \n",
       "2                      0.000000                     0.000000   \n",
       "3                      0.833333                     0.666667   \n",
       "4                      1.220588                     0.941176   \n",
       "\n",
       "   category_1_installments_max  category_1_installments_std  \\\n",
       "0                          0.0                          NaN   \n",
       "1                          1.0                          NaN   \n",
       "2                          0.0                          NaN   \n",
       "3                          1.0                     0.235702   \n",
       "4                          1.5                     0.395148   \n",
       "\n",
       "   authorized_flag_mean  year  month  outliers  \n",
       "0              0.950000  2017      6         0  \n",
       "1              0.968571  2017      1         0  \n",
       "2              0.953488  2016      8         0  \n",
       "3              1.000000  2017      9         0  \n",
       "4              0.962406  2017     11         0  \n",
       "\n",
       "[5 rows x 175 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['card_id', 'first_active_month','outliers']]\n",
    "#categorical_feats = [c for c in features if 'feature_' in c]\n",
    "categorical_feats = ['feature_1','feature_2', 'feature_3','year','month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'elasped_time',\n",
       " 'hist_hist_transactions_count',\n",
       " 'hist_category_1_sum',\n",
       " 'hist_category_1_mean',\n",
       " 'hist_category_2_1.0_mean',\n",
       " 'hist_category_2_2.0_mean',\n",
       " 'hist_category_2_3.0_mean',\n",
       " 'hist_category_2_4.0_mean',\n",
       " 'hist_category_2_5.0_mean',\n",
       " 'hist_category_3_A_mean',\n",
       " 'hist_category_3_B_mean',\n",
       " 'hist_category_3_C_mean',\n",
       " 'hist_merchant_id_nunique',\n",
       " 'hist_merchant_category_id_nunique',\n",
       " 'hist_state_id_nunique',\n",
       " 'hist_city_id_nunique',\n",
       " 'hist_subsector_id_nunique',\n",
       " 'hist_year_nunique',\n",
       " 'hist_month_nunique',\n",
       " 'hist_weekofyear_nunique',\n",
       " 'hist_weekend_sum',\n",
       " 'hist_weekend_mean',\n",
       " 'hist_weekday_sum',\n",
       " 'hist_weekday_mean',\n",
       " 'hist_purchase_amount_sum',\n",
       " 'hist_purchase_amount_median',\n",
       " 'hist_purchase_amount_max',\n",
       " 'hist_purchase_amount_min',\n",
       " 'hist_purchase_amount_std',\n",
       " 'hist_installments_sum',\n",
       " 'hist_installments_median',\n",
       " 'hist_installments_max',\n",
       " 'hist_installments_min',\n",
       " 'hist_installments_std',\n",
       " 'hist_purchase_date_ptp',\n",
       " 'hist_month_lag_min',\n",
       " 'hist_month_lag_max',\n",
       " 'hist_month_lag_mean',\n",
       " 'hist_month_lag_std',\n",
       " 'hist_month_diff_mean',\n",
       " 'hist_authorized_flag_sum',\n",
       " 'hist_authorized_flag_mean',\n",
       " 'auth_hist_transactions_count',\n",
       " 'auth_category_1_sum',\n",
       " 'auth_category_1_mean',\n",
       " 'auth_category_2_1.0_mean',\n",
       " 'auth_category_2_2.0_mean',\n",
       " 'auth_category_2_3.0_mean',\n",
       " 'auth_category_2_4.0_mean',\n",
       " 'auth_category_2_5.0_mean',\n",
       " 'auth_category_3_A_mean',\n",
       " 'auth_category_3_B_mean',\n",
       " 'auth_category_3_C_mean',\n",
       " 'auth_merchant_id_nunique',\n",
       " 'auth_merchant_category_id_nunique',\n",
       " 'auth_state_id_nunique',\n",
       " 'auth_city_id_nunique',\n",
       " 'auth_subsector_id_nunique',\n",
       " 'auth_year_nunique',\n",
       " 'auth_month_nunique',\n",
       " 'auth_weekofyear_nunique',\n",
       " 'auth_weekend_sum',\n",
       " 'auth_weekend_mean',\n",
       " 'auth_weekday_sum',\n",
       " 'auth_weekday_mean',\n",
       " 'auth_purchase_amount_sum',\n",
       " 'auth_purchase_amount_median',\n",
       " 'auth_purchase_amount_max',\n",
       " 'auth_purchase_amount_min',\n",
       " 'auth_purchase_amount_std',\n",
       " 'auth_installments_sum',\n",
       " 'auth_installments_median',\n",
       " 'auth_installments_max',\n",
       " 'auth_installments_min',\n",
       " 'auth_installments_std',\n",
       " 'auth_purchase_date_ptp',\n",
       " 'auth_month_lag_min',\n",
       " 'auth_month_lag_max',\n",
       " 'auth_month_lag_mean',\n",
       " 'auth_month_lag_std',\n",
       " 'auth_month_diff_mean',\n",
       " 'auth_authorized_flag_sum',\n",
       " 'auth_authorized_flag_mean',\n",
       " 'new_hist_transactions_count',\n",
       " 'new_category_1_sum',\n",
       " 'new_category_1_mean',\n",
       " 'new_category_2_1.0_mean',\n",
       " 'new_category_2_2.0_mean',\n",
       " 'new_category_2_3.0_mean',\n",
       " 'new_category_2_4.0_mean',\n",
       " 'new_category_2_5.0_mean',\n",
       " 'new_category_3_A_mean',\n",
       " 'new_category_3_B_mean',\n",
       " 'new_category_3_C_mean',\n",
       " 'new_merchant_id_nunique',\n",
       " 'new_merchant_category_id_nunique',\n",
       " 'new_state_id_nunique',\n",
       " 'new_city_id_nunique',\n",
       " 'new_subsector_id_nunique',\n",
       " 'new_year_nunique',\n",
       " 'new_month_nunique',\n",
       " 'new_weekofyear_nunique',\n",
       " 'new_weekend_sum',\n",
       " 'new_weekend_mean',\n",
       " 'new_weekday_sum',\n",
       " 'new_weekday_mean',\n",
       " 'new_purchase_amount_sum',\n",
       " 'new_purchase_amount_median',\n",
       " 'new_purchase_amount_max',\n",
       " 'new_purchase_amount_min',\n",
       " 'new_purchase_amount_std',\n",
       " 'new_installments_sum',\n",
       " 'new_installments_median',\n",
       " 'new_installments_max',\n",
       " 'new_installments_min',\n",
       " 'new_installments_std',\n",
       " 'new_purchase_date_ptp',\n",
       " 'new_month_lag_min',\n",
       " 'new_month_lag_max',\n",
       " 'new_month_lag_mean',\n",
       " 'new_month_lag_std',\n",
       " 'new_month_diff_mean',\n",
       " 'new_authorized_flag_sum',\n",
       " 'new_authorized_flag_mean',\n",
       " 'month_lag_mean',\n",
       " 'month_lag_std',\n",
       " 'purchase_amount_count_mean',\n",
       " 'purchase_amount_count_std',\n",
       " 'purchase_amount_sum_mean',\n",
       " 'purchase_amount_sum_std',\n",
       " 'purchase_amount_mean_mean',\n",
       " 'purchase_amount_mean_std',\n",
       " 'purchase_amount_min_mean',\n",
       " 'purchase_amount_min_std',\n",
       " 'purchase_amount_max_mean',\n",
       " 'purchase_amount_max_std',\n",
       " 'purchase_amount_std_mean',\n",
       " 'purchase_amount_std_std',\n",
       " 'installments_count_mean',\n",
       " 'installments_count_std',\n",
       " 'installments_sum_mean',\n",
       " 'installments_sum_std',\n",
       " 'installments_mean_mean',\n",
       " 'installments_mean_std',\n",
       " 'installments_min_mean',\n",
       " 'installments_min_std',\n",
       " 'installments_max_mean',\n",
       " 'installments_max_std',\n",
       " 'installments_std_mean',\n",
       " 'installments_std_std',\n",
       " 'category_1_purchase_amount_mean',\n",
       " 'category_1_purchase_amount_min',\n",
       " 'category_1_purchase_amount_max',\n",
       " 'category_1_purchase_amount_std',\n",
       " 'installments_purchase_amount_mean',\n",
       " 'installments_purchase_amount_min',\n",
       " 'installments_purchase_amount_max',\n",
       " 'installments_purchase_amount_std',\n",
       " 'city_id_purchase_amount_mean',\n",
       " 'city_id_purchase_amount_min',\n",
       " 'city_id_purchase_amount_max',\n",
       " 'city_id_purchase_amount_std',\n",
       " 'category_1_installments_mean',\n",
       " 'category_1_installments_min',\n",
       " 'category_1_installments_max',\n",
       " 'category_1_installments_std',\n",
       " 'authorized_flag_mean',\n",
       " 'year',\n",
       " 'month']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective':'regression',\n",
    "         'num_leaves': 31,\n",
    "         'min_data_in_leaf': 25,\n",
    "         'max_depth': 7,\n",
    "         'learning_rate': 0.01,\n",
    "         'lambda_l1':0.13,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\":0.85,\n",
    "         'bagging_freq':8,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"metric\": 'rmse',\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 111,\n",
    "         'min_data_in_leaf': 149, \n",
    "         'objective':'regression',\n",
    "         'max_depth': 9,\n",
    "         'learning_rate': 0.005,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.7522,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.7083 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'rmse',\n",
    "         \"lambda_l1\": 0.2634,\n",
    "         \"random_state\": 133,\n",
    "         \"verbosity\": -1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62871\tvalid_1's rmse: 1.63699\n",
      "[200]\ttraining's rmse: 1.58557\tvalid_1's rmse: 1.59981\n",
      "[300]\ttraining's rmse: 1.56126\tvalid_1's rmse: 1.58164\n",
      "[400]\ttraining's rmse: 1.5456\tvalid_1's rmse: 1.57194\n",
      "[500]\ttraining's rmse: 1.53401\tvalid_1's rmse: 1.56617\n",
      "[600]\ttraining's rmse: 1.52468\tvalid_1's rmse: 1.56251\n",
      "[700]\ttraining's rmse: 1.51661\tvalid_1's rmse: 1.56004\n",
      "[800]\ttraining's rmse: 1.50988\tvalid_1's rmse: 1.55836\n",
      "[900]\ttraining's rmse: 1.5038\tvalid_1's rmse: 1.55709\n",
      "[1000]\ttraining's rmse: 1.49837\tvalid_1's rmse: 1.55614\n",
      "[1100]\ttraining's rmse: 1.49311\tvalid_1's rmse: 1.5554\n",
      "[1200]\ttraining's rmse: 1.48855\tvalid_1's rmse: 1.55485\n",
      "[1300]\ttraining's rmse: 1.48437\tvalid_1's rmse: 1.55438\n",
      "[1400]\ttraining's rmse: 1.48017\tvalid_1's rmse: 1.55409\n",
      "[1500]\ttraining's rmse: 1.47662\tvalid_1's rmse: 1.55392\n",
      "[1600]\ttraining's rmse: 1.47267\tvalid_1's rmse: 1.5537\n",
      "[1700]\ttraining's rmse: 1.46882\tvalid_1's rmse: 1.55357\n",
      "[1800]\ttraining's rmse: 1.4651\tvalid_1's rmse: 1.55342\n",
      "[1900]\ttraining's rmse: 1.46153\tvalid_1's rmse: 1.55329\n",
      "[2000]\ttraining's rmse: 1.45812\tvalid_1's rmse: 1.55324\n",
      "[2100]\ttraining's rmse: 1.45458\tvalid_1's rmse: 1.55319\n",
      "[2200]\ttraining's rmse: 1.45118\tvalid_1's rmse: 1.55321\n",
      "[2300]\ttraining's rmse: 1.44787\tvalid_1's rmse: 1.55318\n",
      "[2400]\ttraining's rmse: 1.44463\tvalid_1's rmse: 1.55322\n",
      "Early stopping, best iteration is:\n",
      "[2246]\ttraining's rmse: 1.44966\tvalid_1's rmse: 1.55316\n",
      "fold 1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62743\tvalid_1's rmse: 1.64386\n",
      "[200]\ttraining's rmse: 1.58433\tvalid_1's rmse: 1.60609\n",
      "[300]\ttraining's rmse: 1.56002\tvalid_1's rmse: 1.58729\n",
      "[400]\ttraining's rmse: 1.54422\tvalid_1's rmse: 1.57729\n",
      "[500]\ttraining's rmse: 1.5325\tvalid_1's rmse: 1.5713\n",
      "[600]\ttraining's rmse: 1.523\tvalid_1's rmse: 1.56748\n",
      "[700]\ttraining's rmse: 1.51503\tvalid_1's rmse: 1.56485\n",
      "[800]\ttraining's rmse: 1.50815\tvalid_1's rmse: 1.5632\n",
      "[900]\ttraining's rmse: 1.50215\tvalid_1's rmse: 1.56186\n",
      "[1000]\ttraining's rmse: 1.49664\tvalid_1's rmse: 1.56102\n",
      "[1100]\ttraining's rmse: 1.49144\tvalid_1's rmse: 1.56037\n",
      "[1200]\ttraining's rmse: 1.48664\tvalid_1's rmse: 1.55981\n",
      "[1300]\ttraining's rmse: 1.48219\tvalid_1's rmse: 1.55939\n",
      "[1400]\ttraining's rmse: 1.47815\tvalid_1's rmse: 1.55906\n",
      "[1500]\ttraining's rmse: 1.47414\tvalid_1's rmse: 1.55879\n",
      "[1600]\ttraining's rmse: 1.4704\tvalid_1's rmse: 1.55862\n",
      "[1700]\ttraining's rmse: 1.46674\tvalid_1's rmse: 1.55847\n",
      "[1800]\ttraining's rmse: 1.46315\tvalid_1's rmse: 1.55822\n",
      "[1900]\ttraining's rmse: 1.45974\tvalid_1's rmse: 1.5582\n",
      "[2000]\ttraining's rmse: 1.45657\tvalid_1's rmse: 1.55814\n",
      "[2100]\ttraining's rmse: 1.45321\tvalid_1's rmse: 1.55814\n",
      "[2200]\ttraining's rmse: 1.44995\tvalid_1's rmse: 1.55813\n",
      "Early stopping, best iteration is:\n",
      "[2071]\ttraining's rmse: 1.45419\tvalid_1's rmse: 1.5581\n",
      "fold 2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.63093\tvalid_1's rmse: 1.6266\n",
      "[200]\ttraining's rmse: 1.58718\tvalid_1's rmse: 1.59096\n",
      "[300]\ttraining's rmse: 1.56247\tvalid_1's rmse: 1.57387\n",
      "[400]\ttraining's rmse: 1.54638\tvalid_1's rmse: 1.565\n",
      "[500]\ttraining's rmse: 1.53449\tvalid_1's rmse: 1.55971\n",
      "[600]\ttraining's rmse: 1.52496\tvalid_1's rmse: 1.55642\n",
      "[700]\ttraining's rmse: 1.51695\tvalid_1's rmse: 1.55419\n",
      "[800]\ttraining's rmse: 1.50995\tvalid_1's rmse: 1.55269\n",
      "[900]\ttraining's rmse: 1.50392\tvalid_1's rmse: 1.5517\n",
      "[1000]\ttraining's rmse: 1.49847\tvalid_1's rmse: 1.55094\n",
      "[1100]\ttraining's rmse: 1.49353\tvalid_1's rmse: 1.55043\n",
      "[1200]\ttraining's rmse: 1.4889\tvalid_1's rmse: 1.55001\n",
      "[1300]\ttraining's rmse: 1.48479\tvalid_1's rmse: 1.54965\n",
      "[1400]\ttraining's rmse: 1.48081\tvalid_1's rmse: 1.54949\n",
      "[1500]\ttraining's rmse: 1.47675\tvalid_1's rmse: 1.54926\n",
      "[1600]\ttraining's rmse: 1.47326\tvalid_1's rmse: 1.54917\n",
      "[1700]\ttraining's rmse: 1.46961\tvalid_1's rmse: 1.54911\n",
      "[1800]\ttraining's rmse: 1.46604\tvalid_1's rmse: 1.54905\n",
      "[1900]\ttraining's rmse: 1.46241\tvalid_1's rmse: 1.54903\n",
      "[2000]\ttraining's rmse: 1.45884\tvalid_1's rmse: 1.549\n",
      "[2100]\ttraining's rmse: 1.45535\tvalid_1's rmse: 1.54895\n",
      "[2200]\ttraining's rmse: 1.45209\tvalid_1's rmse: 1.54892\n",
      "[2300]\ttraining's rmse: 1.44855\tvalid_1's rmse: 1.54896\n",
      "Early stopping, best iteration is:\n",
      "[2163]\ttraining's rmse: 1.45327\tvalid_1's rmse: 1.54891\n",
      "fold 3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62806\tvalid_1's rmse: 1.63994\n",
      "[200]\ttraining's rmse: 1.58494\tvalid_1's rmse: 1.60287\n",
      "[300]\ttraining's rmse: 1.56057\tvalid_1's rmse: 1.58459\n",
      "[400]\ttraining's rmse: 1.54465\tvalid_1's rmse: 1.57479\n",
      "[500]\ttraining's rmse: 1.53272\tvalid_1's rmse: 1.56885\n",
      "[600]\ttraining's rmse: 1.52327\tvalid_1's rmse: 1.56515\n",
      "[700]\ttraining's rmse: 1.51518\tvalid_1's rmse: 1.56268\n",
      "[800]\ttraining's rmse: 1.50832\tvalid_1's rmse: 1.56103\n",
      "[900]\ttraining's rmse: 1.50217\tvalid_1's rmse: 1.55981\n",
      "[1000]\ttraining's rmse: 1.49687\tvalid_1's rmse: 1.55896\n",
      "[1100]\ttraining's rmse: 1.49186\tvalid_1's rmse: 1.55824\n",
      "[1200]\ttraining's rmse: 1.48707\tvalid_1's rmse: 1.55776\n",
      "[1300]\ttraining's rmse: 1.48303\tvalid_1's rmse: 1.5574\n",
      "[1400]\ttraining's rmse: 1.47877\tvalid_1's rmse: 1.55709\n",
      "[1500]\ttraining's rmse: 1.4749\tvalid_1's rmse: 1.55687\n",
      "[1600]\ttraining's rmse: 1.47099\tvalid_1's rmse: 1.55667\n",
      "[1700]\ttraining's rmse: 1.46758\tvalid_1's rmse: 1.55655\n",
      "[1800]\ttraining's rmse: 1.46434\tvalid_1's rmse: 1.55639\n",
      "[1900]\ttraining's rmse: 1.46085\tvalid_1's rmse: 1.55636\n",
      "[2000]\ttraining's rmse: 1.45738\tvalid_1's rmse: 1.55631\n",
      "[2100]\ttraining's rmse: 1.45431\tvalid_1's rmse: 1.55631\n",
      "[2200]\ttraining's rmse: 1.45104\tvalid_1's rmse: 1.55628\n",
      "[2300]\ttraining's rmse: 1.44766\tvalid_1's rmse: 1.55628\n",
      "[2400]\ttraining's rmse: 1.44447\tvalid_1's rmse: 1.5563\n",
      "Early stopping, best iteration is:\n",
      "[2224]\ttraining's rmse: 1.45023\tvalid_1's rmse: 1.55626\n",
      "fold 4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's rmse: 1.62999\tvalid_1's rmse: 1.63105\n",
      "[200]\ttraining's rmse: 1.5865\tvalid_1's rmse: 1.59496\n",
      "[300]\ttraining's rmse: 1.56216\tvalid_1's rmse: 1.57746\n",
      "[400]\ttraining's rmse: 1.54636\tvalid_1's rmse: 1.56811\n",
      "[500]\ttraining's rmse: 1.53462\tvalid_1's rmse: 1.56248\n",
      "[600]\ttraining's rmse: 1.52519\tvalid_1's rmse: 1.5589\n",
      "[700]\ttraining's rmse: 1.51718\tvalid_1's rmse: 1.55651\n",
      "[800]\ttraining's rmse: 1.51039\tvalid_1's rmse: 1.55491\n",
      "[900]\ttraining's rmse: 1.50436\tvalid_1's rmse: 1.55373\n",
      "[1000]\ttraining's rmse: 1.49891\tvalid_1's rmse: 1.55277\n",
      "[1100]\ttraining's rmse: 1.49398\tvalid_1's rmse: 1.55206\n",
      "[1200]\ttraining's rmse: 1.48953\tvalid_1's rmse: 1.55156\n",
      "[1300]\ttraining's rmse: 1.48522\tvalid_1's rmse: 1.55122\n",
      "[1400]\ttraining's rmse: 1.48114\tvalid_1's rmse: 1.5509\n",
      "[1500]\ttraining's rmse: 1.47729\tvalid_1's rmse: 1.55064\n",
      "[1600]\ttraining's rmse: 1.47348\tvalid_1's rmse: 1.55042\n",
      "[1700]\ttraining's rmse: 1.46999\tvalid_1's rmse: 1.55024\n",
      "[1800]\ttraining's rmse: 1.46636\tvalid_1's rmse: 1.55018\n",
      "[1900]\ttraining's rmse: 1.46284\tvalid_1's rmse: 1.55012\n",
      "[2000]\ttraining's rmse: 1.45936\tvalid_1's rmse: 1.55006\n",
      "[2100]\ttraining's rmse: 1.45601\tvalid_1's rmse: 1.55002\n",
      "[2200]\ttraining's rmse: 1.45282\tvalid_1's rmse: 1.54998\n",
      "[2300]\ttraining's rmse: 1.44941\tvalid_1's rmse: 1.55004\n",
      "[2400]\ttraining's rmse: 1.4462\tvalid_1's rmse: 1.55008\n",
      "Early stopping, best iteration is:\n",
      "[2221]\ttraining's rmse: 1.45205\tvalid_1's rmse: 1.54996\n",
      "CV score: 1.55328 \n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=133)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values,target.values)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx],categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx],categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval= 100, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"Feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)**0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers = pd.DataFrame({\"card_id\":test_df[\"card_id\"].values})\n",
    "model_without_outliers[\"target\"] = predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model for outliers classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../train_v4_agg.csv')\n",
    "test_df = pd.read_csv('../test_v4_agg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['outliers'] = 0\n",
    "train_df.loc[train_df['target']<-30,'outliers']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df['outliers']\n",
    "del train_df['outliers']\n",
    "del train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop('Unnamed: 0' ,axis = 1,inplace = True)\n",
    "test_df.drop('Unnamed: 0',axis = 1,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [c for c in train_df.columns if c not in ['card_id', 'first_active_month']]\n",
    "#categorical_feats = [c for c in features if 'feature_' in c]\n",
    "categorical_feats = ['feature_1','feature_2', 'feature_3','year','month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['feature_1',\n",
       " 'feature_2',\n",
       " 'feature_3',\n",
       " 'elasped_time',\n",
       " 'hist_hist_transactions_count',\n",
       " 'hist_category_1_sum',\n",
       " 'hist_category_1_mean',\n",
       " 'hist_category_2_1.0_mean',\n",
       " 'hist_category_2_2.0_mean',\n",
       " 'hist_category_2_3.0_mean',\n",
       " 'hist_category_2_4.0_mean',\n",
       " 'hist_category_2_5.0_mean',\n",
       " 'hist_category_3_A_mean',\n",
       " 'hist_category_3_B_mean',\n",
       " 'hist_category_3_C_mean',\n",
       " 'hist_merchant_id_nunique',\n",
       " 'hist_merchant_category_id_nunique',\n",
       " 'hist_state_id_nunique',\n",
       " 'hist_city_id_nunique',\n",
       " 'hist_subsector_id_nunique',\n",
       " 'hist_year_nunique',\n",
       " 'hist_month_nunique',\n",
       " 'hist_weekofyear_nunique',\n",
       " 'hist_weekend_sum',\n",
       " 'hist_weekend_mean',\n",
       " 'hist_weekday_sum',\n",
       " 'hist_weekday_mean',\n",
       " 'hist_purchase_amount_sum',\n",
       " 'hist_purchase_amount_median',\n",
       " 'hist_purchase_amount_max',\n",
       " 'hist_purchase_amount_min',\n",
       " 'hist_purchase_amount_std',\n",
       " 'hist_installments_sum',\n",
       " 'hist_installments_median',\n",
       " 'hist_installments_max',\n",
       " 'hist_installments_min',\n",
       " 'hist_installments_std',\n",
       " 'hist_purchase_date_ptp',\n",
       " 'hist_month_lag_min',\n",
       " 'hist_month_lag_max',\n",
       " 'hist_month_lag_mean',\n",
       " 'hist_month_lag_std',\n",
       " 'hist_month_diff_mean',\n",
       " 'hist_authorized_flag_sum',\n",
       " 'hist_authorized_flag_mean',\n",
       " 'auth_hist_transactions_count',\n",
       " 'auth_category_1_sum',\n",
       " 'auth_category_1_mean',\n",
       " 'auth_category_2_1.0_mean',\n",
       " 'auth_category_2_2.0_mean',\n",
       " 'auth_category_2_3.0_mean',\n",
       " 'auth_category_2_4.0_mean',\n",
       " 'auth_category_2_5.0_mean',\n",
       " 'auth_category_3_A_mean',\n",
       " 'auth_category_3_B_mean',\n",
       " 'auth_category_3_C_mean',\n",
       " 'auth_merchant_id_nunique',\n",
       " 'auth_merchant_category_id_nunique',\n",
       " 'auth_state_id_nunique',\n",
       " 'auth_city_id_nunique',\n",
       " 'auth_subsector_id_nunique',\n",
       " 'auth_year_nunique',\n",
       " 'auth_month_nunique',\n",
       " 'auth_weekofyear_nunique',\n",
       " 'auth_weekend_sum',\n",
       " 'auth_weekend_mean',\n",
       " 'auth_weekday_sum',\n",
       " 'auth_weekday_mean',\n",
       " 'auth_purchase_amount_sum',\n",
       " 'auth_purchase_amount_median',\n",
       " 'auth_purchase_amount_max',\n",
       " 'auth_purchase_amount_min',\n",
       " 'auth_purchase_amount_std',\n",
       " 'auth_installments_sum',\n",
       " 'auth_installments_median',\n",
       " 'auth_installments_max',\n",
       " 'auth_installments_min',\n",
       " 'auth_installments_std',\n",
       " 'auth_purchase_date_ptp',\n",
       " 'auth_month_lag_min',\n",
       " 'auth_month_lag_max',\n",
       " 'auth_month_lag_mean',\n",
       " 'auth_month_lag_std',\n",
       " 'auth_month_diff_mean',\n",
       " 'auth_authorized_flag_sum',\n",
       " 'auth_authorized_flag_mean',\n",
       " 'new_hist_transactions_count',\n",
       " 'new_category_1_sum',\n",
       " 'new_category_1_mean',\n",
       " 'new_category_2_1.0_mean',\n",
       " 'new_category_2_2.0_mean',\n",
       " 'new_category_2_3.0_mean',\n",
       " 'new_category_2_4.0_mean',\n",
       " 'new_category_2_5.0_mean',\n",
       " 'new_category_3_A_mean',\n",
       " 'new_category_3_B_mean',\n",
       " 'new_category_3_C_mean',\n",
       " 'new_merchant_id_nunique',\n",
       " 'new_merchant_category_id_nunique',\n",
       " 'new_state_id_nunique',\n",
       " 'new_city_id_nunique',\n",
       " 'new_subsector_id_nunique',\n",
       " 'new_year_nunique',\n",
       " 'new_month_nunique',\n",
       " 'new_weekofyear_nunique',\n",
       " 'new_weekend_sum',\n",
       " 'new_weekend_mean',\n",
       " 'new_weekday_sum',\n",
       " 'new_weekday_mean',\n",
       " 'new_purchase_amount_sum',\n",
       " 'new_purchase_amount_median',\n",
       " 'new_purchase_amount_max',\n",
       " 'new_purchase_amount_min',\n",
       " 'new_purchase_amount_std',\n",
       " 'new_installments_sum',\n",
       " 'new_installments_median',\n",
       " 'new_installments_max',\n",
       " 'new_installments_min',\n",
       " 'new_installments_std',\n",
       " 'new_purchase_date_ptp',\n",
       " 'new_month_lag_min',\n",
       " 'new_month_lag_max',\n",
       " 'new_month_lag_mean',\n",
       " 'new_month_lag_std',\n",
       " 'new_month_diff_mean',\n",
       " 'new_authorized_flag_sum',\n",
       " 'new_authorized_flag_mean',\n",
       " 'month_lag_mean',\n",
       " 'month_lag_std',\n",
       " 'purchase_amount_count_mean',\n",
       " 'purchase_amount_count_std',\n",
       " 'purchase_amount_sum_mean',\n",
       " 'purchase_amount_sum_std',\n",
       " 'purchase_amount_mean_mean',\n",
       " 'purchase_amount_mean_std',\n",
       " 'purchase_amount_min_mean',\n",
       " 'purchase_amount_min_std',\n",
       " 'purchase_amount_max_mean',\n",
       " 'purchase_amount_max_std',\n",
       " 'purchase_amount_std_mean',\n",
       " 'purchase_amount_std_std',\n",
       " 'installments_count_mean',\n",
       " 'installments_count_std',\n",
       " 'installments_sum_mean',\n",
       " 'installments_sum_std',\n",
       " 'installments_mean_mean',\n",
       " 'installments_mean_std',\n",
       " 'installments_min_mean',\n",
       " 'installments_min_std',\n",
       " 'installments_max_mean',\n",
       " 'installments_max_std',\n",
       " 'installments_std_mean',\n",
       " 'installments_std_std',\n",
       " 'category_1_purchase_amount_mean',\n",
       " 'category_1_purchase_amount_min',\n",
       " 'category_1_purchase_amount_max',\n",
       " 'category_1_purchase_amount_std',\n",
       " 'installments_purchase_amount_mean',\n",
       " 'installments_purchase_amount_min',\n",
       " 'installments_purchase_amount_max',\n",
       " 'installments_purchase_amount_std',\n",
       " 'city_id_purchase_amount_mean',\n",
       " 'city_id_purchase_amount_min',\n",
       " 'city_id_purchase_amount_max',\n",
       " 'city_id_purchase_amount_std',\n",
       " 'category_1_installments_mean',\n",
       " 'category_1_installments_min',\n",
       " 'category_1_installments_max',\n",
       " 'category_1_installments_std',\n",
       " 'authorized_flag_mean',\n",
       " 'year',\n",
       " 'month']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'num_leaves': 31,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'binary',\n",
    "         'max_depth': 6,\n",
    "         'learning_rate': 0.01,\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'binary_logloss',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1,\n",
    "         \"random_state\": 2333}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°0\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0431461\tvalid_1's binary_logloss: 0.0471357\n",
      "[200]\ttraining's binary_logloss: 0.0393119\tvalid_1's binary_logloss: 0.0451603\n",
      "[300]\ttraining's binary_logloss: 0.0369321\tvalid_1's binary_logloss: 0.0445454\n",
      "[400]\ttraining's binary_logloss: 0.035152\tvalid_1's binary_logloss: 0.0443119\n",
      "[500]\ttraining's binary_logloss: 0.0335519\tvalid_1's binary_logloss: 0.044214\n",
      "[600]\ttraining's binary_logloss: 0.0320973\tvalid_1's binary_logloss: 0.0441767\n",
      "[700]\ttraining's binary_logloss: 0.0306716\tvalid_1's binary_logloss: 0.0441624\n",
      "[800]\ttraining's binary_logloss: 0.0294403\tvalid_1's binary_logloss: 0.044192\n",
      "Early stopping, best iteration is:\n",
      "[674]\ttraining's binary_logloss: 0.0310365\tvalid_1's binary_logloss: 0.0441595\n",
      "fold n°1\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0435314\tvalid_1's binary_logloss: 0.0457959\n",
      "[200]\ttraining's binary_logloss: 0.039635\tvalid_1's binary_logloss: 0.0439941\n",
      "[300]\ttraining's binary_logloss: 0.037195\tvalid_1's binary_logloss: 0.043428\n",
      "[400]\ttraining's binary_logloss: 0.0353823\tvalid_1's binary_logloss: 0.0432558\n",
      "[500]\ttraining's binary_logloss: 0.0337516\tvalid_1's binary_logloss: 0.0431607\n",
      "[600]\ttraining's binary_logloss: 0.0321753\tvalid_1's binary_logloss: 0.0431333\n",
      "[700]\ttraining's binary_logloss: 0.0307139\tvalid_1's binary_logloss: 0.0431613\n",
      "Early stopping, best iteration is:\n",
      "[572]\ttraining's binary_logloss: 0.0325979\tvalid_1's binary_logloss: 0.0431195\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0437461\tvalid_1's binary_logloss: 0.0450522\n",
      "[200]\ttraining's binary_logloss: 0.0398321\tvalid_1's binary_logloss: 0.0432826\n",
      "[300]\ttraining's binary_logloss: 0.0374382\tvalid_1's binary_logloss: 0.0427124\n",
      "[400]\ttraining's binary_logloss: 0.035705\tvalid_1's binary_logloss: 0.0424971\n",
      "[500]\ttraining's binary_logloss: 0.0341146\tvalid_1's binary_logloss: 0.0424029\n",
      "[600]\ttraining's binary_logloss: 0.0325473\tvalid_1's binary_logloss: 0.0423724\n",
      "[700]\ttraining's binary_logloss: 0.0311045\tvalid_1's binary_logloss: 0.0423819\n",
      "[800]\ttraining's binary_logloss: 0.0298459\tvalid_1's binary_logloss: 0.0423843\n",
      "Early stopping, best iteration is:\n",
      "[638]\ttraining's binary_logloss: 0.0320223\tvalid_1's binary_logloss: 0.0423531\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.0425418\tvalid_1's binary_logloss: 0.0497107\n",
      "[200]\ttraining's binary_logloss: 0.0387243\tvalid_1's binary_logloss: 0.0477396\n",
      "[300]\ttraining's binary_logloss: 0.0363297\tvalid_1's binary_logloss: 0.0471946\n",
      "[400]\ttraining's binary_logloss: 0.0345206\tvalid_1's binary_logloss: 0.047043\n",
      "[500]\ttraining's binary_logloss: 0.0329163\tvalid_1's binary_logloss: 0.0469967\n",
      "[600]\ttraining's binary_logloss: 0.0314102\tvalid_1's binary_logloss: 0.0470354\n",
      "Early stopping, best iteration is:\n",
      "[498]\ttraining's binary_logloss: 0.032945\tvalid_1's binary_logloss: 0.0469962\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "[100]\ttraining's binary_logloss: 0.043477\tvalid_1's binary_logloss: 0.0455266\n",
      "[200]\ttraining's binary_logloss: 0.0395561\tvalid_1's binary_logloss: 0.0437713\n",
      "[300]\ttraining's binary_logloss: 0.0371678\tvalid_1's binary_logloss: 0.0432448\n",
      "[400]\ttraining's binary_logloss: 0.035416\tvalid_1's binary_logloss: 0.043097\n",
      "[500]\ttraining's binary_logloss: 0.0337632\tvalid_1's binary_logloss: 0.0430823\n",
      "[600]\ttraining's binary_logloss: 0.0322453\tvalid_1's binary_logloss: 0.0430732\n",
      "[700]\ttraining's binary_logloss: 0.0308017\tvalid_1's binary_logloss: 0.0431144\n",
      "Early stopping, best iteration is:\n",
      "[582]\ttraining's binary_logloss: 0.0325198\tvalid_1's binary_logloss: 0.0430689\n",
      "CV score: 0.04394 \n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=5, shuffle=True, random_state=15)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"fold n°{}\".format(fold_))\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][features], label=target.iloc[trn_idx], categorical_feature=categorical_feats)\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][features], label=target.iloc[val_idx], categorical_feature=categorical_feats)\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=100, early_stopping_rounds = 200)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][features], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    fold_importance_df = pd.DataFrame()\n",
    "    fold_importance_df[\"feature\"] = features\n",
    "    fold_importance_df[\"importance\"] = clf.feature_importance()\n",
    "    fold_importance_df[\"fold\"] = fold_ + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
    "    \n",
    "    predictions += clf.predict(test_df[features], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(log_loss(target, oof)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>0.121800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_130fd0cbdd</td>\n",
       "      <td>0.002262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>0.012658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_d27d835a9f</td>\n",
       "      <td>0.000173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_2b5e3df5c2</td>\n",
       "      <td>0.002207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab  0.121800\n",
       "1  C_ID_130fd0cbdd  0.002262\n",
       "2  C_ID_b709037bc5  0.012658\n",
       "3  C_ID_d27d835a9f  0.000173\n",
       "4  C_ID_2b5e3df5c2  0.002207"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_outlier_prob = pd.DataFrame({\"card_id\":test_df[\"card_id\"].values})\n",
    "df_outlier_prob[\"target\"] = predictions\n",
    "df_outlier_prob.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case missing some predictable outlier, we choose top 25000 with highest outliers likelyhood.\n",
    "outlier_id = pd.DataFrame(df_outlier_prob.sort_values(by='target',ascending = False).head(25000)['card_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_submission = pd.read_csv('../3.695.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card_id</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C_ID_0ab67a22ab</td>\n",
       "      <td>-2.502326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C_ID_b709037bc5</td>\n",
       "      <td>-0.959266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C_ID_f7cada36d3</td>\n",
       "      <td>0.411326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C_ID_6d8dba8475</td>\n",
       "      <td>-0.893964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C_ID_7f1041e8e1</td>\n",
       "      <td>-4.872942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           card_id    target\n",
       "0  C_ID_0ab67a22ab -2.502326\n",
       "1  C_ID_b709037bc5 -0.959266\n",
       "2  C_ID_f7cada36d3  0.411326\n",
       "3  C_ID_6d8dba8475 -0.893964\n",
       "4  C_ID_7f1041e8e1 -4.872942"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "most_likely_liers = best_submission.merge(outlier_id,how='right')\n",
    "most_likely_liers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#for card_id in most_likely_liers['card_id']:\n",
    "#    model_without_outliers.loc[model_without_outliers['card_id']==card_id,'target']\\\n",
    "#    = most_likely_liers.loc[most_likely_liers['card_id']==card_id,'target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "ix1 = model_without_outliers[\"card_id\"].isin(outlier_id[\"card_id\"].values)\n",
    "ix2 = best_submission[\"card_id\"].isin(outlier_id[\"card_id\"].values)\n",
    "model_without_outliers.loc[ix1, \"target\"] = best_submission[ix2][\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_outliers.to_csv(\"../submit_v4_combining.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
